# üèóÔ∏è Arquitectura del M√≥dulo Upload

## üìã Resumen Ejecutivo

El m√≥dulo de upload est√° dise√±ado para procesar archivos BCRA de gran tama√±o (hasta 10GB) de manera eficiente y escalable, utilizando streaming, procesamiento por chunks y almacenamiento distribuido.

## üéØ Objetivos de Dise√±o

### Performance
- **Procesamiento de archivos de 5GB+**: Streaming real sin cargar en memoria
- **Velocidad**: Procesamiento de 100K+ l√≠neas por segundo
- **Eficiencia**: Uso m√≠nimo de memoria (<100MB independiente del tama√±o del archivo)

### Escalabilidad
- **Horizontal**: M√∫ltiples instancias pueden procesar archivos simult√°neamente
- **Vertical**: Optimizaci√≥n para archivos de cualquier tama√±o
- **El√°stica**: Adaptaci√≥n autom√°tica a la carga

### Resiliencia
- **Fault tolerance**: Continuaci√≥n ante errores de l√≠nea individual
- **Recovery**: Recuperaci√≥n de importaciones interrumpidas
- **Audit trail**: Trazabilidad completa de todas las operaciones

## üèõÔ∏è Arquitectura de Alto Nivel

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   HTTP Client   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Upload Module  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   DynamoDB      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   LocalStack    ‚îÇ
                       ‚îÇ   (S3 + SQS)    ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîß Componentes Principales

### 1. UploadController
**Responsabilidad**: Manejo de requests HTTP y validaci√≥n de archivos

**Caracter√≠sticas**:
- Validaci√≥n de tipo de archivo (.txt)
- L√≠mite de tama√±o (10GB)
- Interceptaci√≥n de archivos multipart
- Documentaci√≥n Swagger autom√°tica

**Flujo**:
```typescript
@Post('/upload')
async uploadFile(@UploadedFile() file: Express.Multer.File) {
  // 1. Validar archivo
  // 2. Delegar a UploadService
  // 3. Retornar respuesta
}
```

### 2. UploadService
**Responsabilidad**: Orquestaci√≥n del proceso de importaci√≥n

**Caracter√≠sticas**:
- Coordinaci√≥n de todos los servicios
- Manejo de estado de importaci√≥n
- Gesti√≥n de errores y recuperaci√≥n
- M√©tricas de rendimiento

**Flujo Principal**:
```typescript
async processFile(file: any): Promise<UploadResult> {
  // 1. Crear registro de importaci√≥n
  // 2. Subir archivo a S3 (streaming)
  // 3. Procesar archivo (streaming)
  // 4. Actualizar estad√≠sticas
  // 5. Retornar resultado
}
```

### 3. S3Service
**Responsabilidad**: Almacenamiento de archivos en S3

**Caracter√≠sticas**:
- Upload multiparte para archivos grandes
- Streaming directo sin buffer intermedio
- Configuraci√≥n optimizada para LocalStack
- Manejo de errores de red

**Implementaci√≥n**:
```typescript
async uploadFileStream(stream: Readable, key: string): Promise<void> {
  const upload = new Upload({
    client: this.s3Client,
    params: { Bucket: this.bucketName, Key: key, Body: stream },
    queueSize: 4,        // 4 partes concurrentes
    partSize: 5 * 1024 * 1024, // 5MB por parte
  });
  await upload.done();
}
```

### 4. BcraLineParser
**Responsabilidad**: Parsing y validaci√≥n de l√≠neas BCRA

**Caracter√≠sticas**:
- Parsing de longitud fija (41 caracteres)
- Validaci√≥n de tipos de datos
- Manejo de l√≠neas incompletas
- Logging de errores detallado

**Estructura de Parsing**:
```typescript
parseLine(line: string): BcraLineData | null {
  // Validar longitud m√≠nima
  if (line.length < 41) return null;
  
  // Extraer campos por posici√≥n
  return {
    codigoEntidad: line.substring(0, 5),
    fechaInformacion: line.substring(5, 11),
    // ... otros campos
  };
}
```

### 5. Repositorios DynamoDB

#### ImportacionRepository
**Responsabilidad**: Gesti√≥n de registros de importaci√≥n

**Operaciones**:
- `crear()`: Nuevo registro de importaci√≥n
- `actualizarEstadisticas()`: Actualizar contadores y estado
- `obtenerPorId()`: Consultar importaci√≥n espec√≠fica

#### DeudorImportadoRepository
**Responsabilidad**: Almacenamiento de datos de deudores

**Operaciones**:
- `crear()`: Guardar deudor importado
- `obtenerPorCuit()`: Consultar por CUIT
- `obtenerPorImportacion()`: Listar por importaci√≥n (GSI)

#### ErrorImportacionRepository
**Responsabilidad**: Log de errores de importaci√≥n

**Operaciones**:
- `crear()`: Registrar error de l√≠nea
- `obtenerPorImportacion()`: Listar errores por importaci√≥n (GSI)

## üîÑ Flujo de Datos Detallado

### 1. Recepci√≥n de Archivo
```
HTTP Request ‚Üí Multer ‚Üí FileInterceptor ‚Üí UploadController
```

### 2. Inicializaci√≥n
```
UploadController ‚Üí UploadService ‚Üí ImportacionRepository.crear()
```

### 3. Upload a S3
```
File Stream ‚Üí S3Service.uploadFileStream() ‚Üí LocalStack S3
```

### 4. Procesamiento por Streaming
```
File Stream ‚Üí Transform Stream ‚Üí Line Processing ‚Üí DynamoDB
```

### 5. Finalizaci√≥n
```
UploadService ‚Üí ImportacionRepository.actualizarEstadisticas() ‚Üí Response
```

## üìä Modelo de Datos

### Tabla: importaciones_bcra
```typescript
interface Importacion {
  id: string;                    // PK - UUID
  nombreArchivo: string;         // Nombre original
  fechaImportacion: string;      // ISO timestamp
  estado: 'en_proceso' | 'completado' | 'error';
  cantidadRegistros: number;     // L√≠neas exitosas
  cantidadErrores: number;       // L√≠neas con error
  s3Key: string;                 // Ubicaci√≥n S3
  tamanoArchivo: number;         // Bytes
  tipoArchivo: string;           // MIME type
}
```

### Tabla: deudores_bcra
```typescript
interface DeudorImportado {
  cuit: string;                  // PK - CUIT
  importacionId: string;         // GSI - Referencia
  // Campos del archivo BCRA
  codigoEntidad: string;
  fechaInformacion: string;
  tipoIdentificacion: string;
  numeroIdentificacion: string;
  actividad: string;
  situacion: number;
  prestamosGarantias: number;
  // Metadatos
  fechaImportacion: string;
  lineaArchivo: number;
}
```

### Tabla: importaciones_errores
```typescript
interface ErrorImportacion {
  id: string;                    // PK - UUID
  importacionId: string;         // GSI - Referencia
  linea: number;                 // N√∫mero de l√≠nea
  error: string;                 // Descripci√≥n
  contenidoLinea?: string;       // Contenido problem√°tico
  timestamp: string;             // ISO timestamp
  tipoError: 'parsing' | 'validacion' | 'persistencia' | 'otro';
}
```

## üîß Optimizaciones Implementadas

### 1. Streaming de Archivos
```typescript
// Procesamiento l√≠nea por l√≠nea sin cargar en memoria
const lineProcessor = new Transform({
  transform: async (chunk: Buffer, encoding: string, callback: Function) => {
    // Procesar chunk de 64KB
    // Extraer l√≠neas completas
    // Procesar cada l√≠nea
    callback();
  }
});
```

### 2. Upload Multiparte a S3
```typescript
const upload = new Upload({
  client: this.s3Client,
  params: { Bucket: this.bucketName, Key: key, Body: stream },
  queueSize: 4,        // Concurrencia
  partSize: 5 * 1024 * 1024, // Tama√±o de parte
});
```

### 3. Buffering Inteligente
```typescript
// Manejo de l√≠neas incompletas entre chunks
let buffer = '';
const lines = buffer.split('\n');
buffer = lines.pop() || ''; // Mantener l√≠nea incompleta
```

### 4. Procesamiento As√≠ncrono
```typescript
// Operaciones de base de datos no bloqueantes
await Promise.all([
  this.deudorImportadoRepository.crear(deudor),
  this.registerDeudorUseCase.execute(cuit, situacion, monto)
]);
```

## üö® Manejo de Errores

### Estrategia de Recuperaci√≥n
1. **Errores de L√≠nea Individual**: Continuar procesamiento
2. **Errores de Base de Datos**: Reintentar con backoff exponencial
3. **Errores de S3**: Fallback a almacenamiento local
4. **Errores Cr√≠ticos**: Marcar importaci√≥n como fallida

### Logging Estructurado
```typescript
this.logger.log('Archivo procesado', {
  importacionId,
  processedLines,
  cantidadErrores,
  tiempoProcesamiento,
  tamanoArchivo
});
```

## üìà M√©tricas y Monitoreo

### M√©tricas Clave
- **Throughput**: L√≠neas procesadas por segundo
- **Latencia**: Tiempo total de procesamiento
- **Error Rate**: Porcentaje de l√≠neas con error
- **Memory Usage**: Consumo de memoria durante procesamiento

### Alertas Recomendadas
- Error rate > 5%
- Processing time > 30 minutes para archivos < 1GB
- Memory usage > 200MB
- S3 upload failures > 3

## üîÆ Consideraciones Futuras

### Escalabilidad Horizontal
- **SQS Integration**: Cola de procesamiento para m√∫ltiples workers
- **Lambda Processing**: Procesamiento serverless para archivos muy grandes
- **Sharding**: Divisi√≥n de archivos grandes en chunks procesables

### Optimizaciones Adicionales
- **Batch Writes**: Agrupaci√≥n de operaciones DynamoDB
- **Connection Pooling**: Reutilizaci√≥n de conexiones
- **Caching**: Cache de configuraciones y validaciones
- **Compression**: Compresi√≥n de archivos antes del upload

### Monitoreo Avanzado
- **Distributed Tracing**: Trazabilidad con Jaeger/Zipkin
- **Custom Metrics**: M√©tricas espec√≠ficas del dominio
- **Health Checks**: Endpoints de salud del m√≥dulo
- **Performance Profiling**: An√°lisis detallado de bottlenecks 